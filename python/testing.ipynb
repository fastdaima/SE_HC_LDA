{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirakr/miniconda3/envs/fastai_l/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique tokens: 4183\n",
      "number of documents : 3227\n",
      "cluster no: 9\n",
      "0    1508\n",
      "1     327\n",
      "7     246\n",
      "4     222\n",
      "3     211\n",
      "2     194\n",
      "5     190\n",
      "6     187\n",
      "8     142\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from text_preprocessing import text_processing\n",
    "\n",
    "import string\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from gensim import corpora, models\n",
    "import pandas as pd\n",
    "from nltk import WordNetLemmatizer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from nltk.corpus import *\n",
    "from nltk.tokenize import *\n",
    "import contractions\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.metrics import *\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "def return_dict_corpus(train_df):\n",
    "    texts = list(train_df.lemmatize_title_w_pos.values)\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    print(f'number of unique tokens: {len(dictionary)}')\n",
    "    print(f'number of documents : {len(corpus)}')\n",
    "\n",
    "    return texts, dictionary, corpus\n",
    "\n",
    "\n",
    "path = Path(r'../Tawosi_Dataset')\n",
    "\n",
    "train, valid, test = pd.read_csv(path / 'DM-train.csv'), pd.read_csv(path / 'DM-valid.csv'), pd.read_csv(\n",
    "    path / 'DM-test.csv')\n",
    "\n",
    "data = pd.concat([train, valid])\n",
    "\n",
    "texts = []\n",
    "\n",
    "# print(train)\n",
    "\n",
    "train = text_processing(train)\n",
    "\n",
    "texts, dictionary, corpus = return_dict_corpus(train)\n",
    "\n",
    "num_topics = 20\n",
    "\n",
    "lda_model = models.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=num_topics,\n",
    "    random_state=100,\n",
    "    chunksize=2000,\n",
    "    iterations=400,\n",
    "    passes=20,\n",
    "    per_word_topics=True,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    eval_every=True\n",
    ")\n",
    "\n",
    "topics = lda_model[corpus]\n",
    "\n",
    "train_ik = train.issuekey.values\n",
    "\n",
    "\n",
    "test_prob = {}\n",
    "\n",
    "topics_number = set(f'topic_{i}' for i in range(num_topics))\n",
    "\n",
    "for key, prob in zip(train_ik, topics):\n",
    "    top_preds = {}\n",
    "\n",
    "    for (topic_no, value) in prob[0]:\n",
    "        top_preds[f'topic_{topic_no}'] = value\n",
    "\n",
    "\n",
    "    for tn in topics_number:\n",
    "        if not top_preds.get(tn, None):\n",
    "            top_preds[tn] = 0.0\n",
    "\n",
    "    test_prob[key] = top_preds\n",
    "\n",
    "\n",
    "prob_df_cols = sorted(list(topics_number), key=lambda x: int(x.split('_')[1]))\n",
    "\n",
    "prob_df = pd.DataFrame.from_dict(test_prob, orient='index')\n",
    "\n",
    "prob_df.index.name = 'issuekey'\n",
    "\n",
    "prob_df.to_csv('prob_df.csv')\n",
    "\n",
    "dendrogram = sch.dendrogram(sch.linkage(prob_df.values, method='ward'), no_plot=True)\n",
    "\n",
    "cn = len(set(dendrogram['color_list'])) - 1\n",
    "\n",
    "print(f\"cluster no: {cn}\")\n",
    "\n",
    "ac_m = AgglomerativeClustering(n_clusters=cn, affinity='euclidean', linkage='ward')\n",
    "\n",
    "preds = ac_m.fit_predict(prob_df.values)\n",
    "\n",
    "prob_df['labels'] = preds\n",
    "\n",
    "print(prob_df.labels.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique tokens: 1936\n",
      "number of documents : 1078\n"
     ]
    }
   ],
   "source": [
    "test_df = text_processing(test)\n",
    "t_texts, t_dictionary, t_corpus = return_dict_corpus(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "t_topics = lda_model[t_corpus[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "([(3, 0.17525354),\n  (4, 0.5068754),\n  (6, 0.010642398),\n  (11, 0.010100877),\n  (16, 0.010015527),\n  (18, 0.17296453)],\n [(0, [4]), (1, [4]), (2, [4]), (3, [18]), (4, [3])],\n [(0, [(4, 0.9999258)]),\n  (1, [(4, 0.9999708)]),\n  (2, [(4, 0.9997431)]),\n  (3, [(18, 0.9996705)]),\n  (4, [(3, 0.99963593)])])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_topics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def return_prob_list(probs):\n",
    "    ind_prob = {}\n",
    "\n",
    "    for (topic_no, prob) in probs[0]:\n",
    "        ind_prob[f'topic_{topic_no}'] = prob\n",
    "\n",
    "    for tn in topics_number:\n",
    "        if not ind_prob.get(tn, None): ind_prob[tn] = 0.0\n",
    "\n",
    "    return ind_prob\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'topic_3': 0.17525354,\n 'topic_4': 0.5068754,\n 'topic_6': 0.010642398,\n 'topic_11': 0.010100877,\n 'topic_16': 0.010015527,\n 'topic_18': 0.17296453,\n 'topic_12': 0.0,\n 'topic_19': 0.0,\n 'topic_15': 0.0,\n 'topic_9': 0.0,\n 'topic_14': 0.0,\n 'topic_10': 0.0,\n 'topic_0': 0.0,\n 'topic_17': 0.0,\n 'topic_13': 0.0,\n 'topic_1': 0.0,\n 'topic_2': 0.0,\n 'topic_5': 0.0,\n 'topic_7': 0.0,\n 'topic_8': 0.0}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prob_list(t_topics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "inp = list(dict(sorted(return_prob_list(t_topics).items(), key= lambda item: int(item[0].split('_')[1]))).values())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "inps = {\n",
    "    'inp-6767': return_prob_list(t_topics)\n",
    "}\n",
    "\n",
    "inp_df = pd.DataFrame.from_dict(inps, orient='index')\n",
    "inp_df.index.name = 'issue_key'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# ac_m.fit_predict(inp_df.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.17525354, 0.5068754 , 0.0106424 , 0.01010088, 0.01001553,\n        0.17296453, 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ]])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_df.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 1 sample(s) (shape=(1, 20)) while a minimum of 2 is required by AgglomerativeClustering.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_101069/1685944029.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mac_m\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_predict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minp_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/miniconda3/envs/fastai_l/lib/python3.9/site-packages/sklearn/cluster/_agglomerative.py\u001B[0m in \u001B[0;36mfit_predict\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m   1052\u001B[0m             \u001B[0mCluster\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \"\"\"\n\u001B[0;32m-> 1054\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_predict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1055\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1056\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/fastai_l/lib/python3.9/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36mfit_predict\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    734\u001B[0m         \u001B[0;31m# non-optimized default implementation; override when a better\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    735\u001B[0m         \u001B[0;31m# method is possible for a given clustering algorithm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 736\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    737\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    738\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/fastai_l/lib/python3.9/site-packages/sklearn/cluster/_agglomerative.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    915\u001B[0m             \u001B[0mReturns\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mfitted\u001B[0m \u001B[0minstance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    916\u001B[0m         \"\"\"\n\u001B[0;32m--> 917\u001B[0;31m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mensure_min_samples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mestimator\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    918\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    919\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/fastai_l/lib/python3.9/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    564\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Validation should be done on X, y or both.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    565\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 566\u001B[0;31m             \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    567\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    568\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/fastai_l/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    803\u001B[0m         \u001B[0mn_samples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    804\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mn_samples\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mensure_min_samples\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 805\u001B[0;31m             raise ValueError(\n\u001B[0m\u001B[1;32m    806\u001B[0m                 \u001B[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    807\u001B[0m                 \u001B[0;34m\" minimum of %d is required%s.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Found array with 1 sample(s) (shape=(1, 20)) while a minimum of 2 is required by AgglomerativeClustering."
     ]
    }
   ],
   "source": [
    "ac_m.fit_predict(inp_df.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "(3227, 21)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 20)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "array([4, 7, 5, 6, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1])"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_m.fit_predict(inp_df.to_numpy().reshape(-1,1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "           topic_3   topic_4   topic_6  topic_11  topic_16  topic_18  \\\nissuekey                                                               \nDM-9      0.175254  0.506875  0.010642  0.010101  0.010016  0.172965   \nDM-71     0.011095  0.010498  0.012759  0.012110  0.211073  0.000000   \nDM-68     0.000000  0.423613  0.010641  0.010100  0.010015  0.000000   \nDM-52     0.330720  0.242236  0.012760  0.012110  0.256973  0.000000   \nDM-78     0.000000  0.000000  0.010642  0.010101  0.010015  0.837085   \n...            ...       ...       ...       ...       ...       ...   \nDM-16286  0.116978  0.000000  0.000000  0.000000  0.000000  0.000000   \nDM-18223  0.000000  0.000000  0.000000  0.000000  0.000000  0.129856   \nDM-18209  0.000000  0.000000  0.000000  0.000000  0.154350  0.148349   \nDM-16305  0.018436  0.017443  0.021201  0.020122  0.019952  0.013864   \nDM-16304  0.349271  0.017445  0.351930  0.020124  0.019954  0.013865   \n\n          topic_12  topic_19  topic_15   topic_9  ...  topic_10   topic_0  \\\nissuekey                                          ...                       \nDM-9      0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \nDM-71     0.010207  0.011319  0.000000  0.010514  ...  0.011525  0.000000   \nDM-68     0.000000  0.212937  0.000000  0.000000  ...  0.221396  0.000000   \nDM-52     0.010207  0.011319  0.000000  0.010514  ...  0.011526  0.000000   \nDM-78     0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n...            ...       ...       ...       ...  ...       ...       ...   \nDM-16286  0.000000  0.000000  0.000000  0.000000  ...  0.560591  0.000000   \nDM-18223  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \nDM-18209  0.000000  0.000000  0.000000  0.000000  ...  0.150610  0.000000   \nDM-16305  0.016960  0.018808  0.015973  0.017469  ...  0.019150  0.015363   \nDM-16304  0.016961  0.018809  0.015974  0.017470  ...  0.019152  0.015364   \n\n          topic_17  topic_13   topic_1   topic_2   topic_5   topic_7  \\\nissuekey                                                               \nDM-9      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \nDM-71     0.000000  0.000000  0.607230  0.000000  0.000000  0.000000   \nDM-68     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \nDM-52     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \nDM-78     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n...            ...       ...       ...       ...       ...       ...   \nDM-16286  0.000000  0.000000  0.227189  0.000000  0.000000  0.000000   \nDM-18223  0.000000  0.000000  0.141204  0.000000  0.000000  0.000000   \nDM-18209  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \nDM-16305  0.016178  0.013489  0.016555  0.015846  0.013893  0.016012   \nDM-16304  0.016180  0.013490  0.016557  0.015847  0.013894  0.016013   \n\n           topic_8  labels  \nissuekey                    \nDM-9      0.000000       0  \nDM-71     0.000000       1  \nDM-68     0.000000       6  \nDM-52     0.000000       4  \nDM-78     0.000000       0  \n...            ...     ...  \nDM-16286  0.000000       2  \nDM-18223  0.254563       0  \nDM-18209  0.000000       8  \nDM-16305  0.675587       0  \nDM-16304  0.013999       0  \n\n[3227 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_3</th>\n      <th>topic_4</th>\n      <th>topic_6</th>\n      <th>topic_11</th>\n      <th>topic_16</th>\n      <th>topic_18</th>\n      <th>topic_12</th>\n      <th>topic_19</th>\n      <th>topic_15</th>\n      <th>topic_9</th>\n      <th>...</th>\n      <th>topic_10</th>\n      <th>topic_0</th>\n      <th>topic_17</th>\n      <th>topic_13</th>\n      <th>topic_1</th>\n      <th>topic_2</th>\n      <th>topic_5</th>\n      <th>topic_7</th>\n      <th>topic_8</th>\n      <th>labels</th>\n    </tr>\n    <tr>\n      <th>issuekey</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>DM-9</th>\n      <td>0.175254</td>\n      <td>0.506875</td>\n      <td>0.010642</td>\n      <td>0.010101</td>\n      <td>0.010016</td>\n      <td>0.172965</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>DM-71</th>\n      <td>0.011095</td>\n      <td>0.010498</td>\n      <td>0.012759</td>\n      <td>0.012110</td>\n      <td>0.211073</td>\n      <td>0.000000</td>\n      <td>0.010207</td>\n      <td>0.011319</td>\n      <td>0.000000</td>\n      <td>0.010514</td>\n      <td>...</td>\n      <td>0.011525</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.607230</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>DM-68</th>\n      <td>0.000000</td>\n      <td>0.423613</td>\n      <td>0.010641</td>\n      <td>0.010100</td>\n      <td>0.010015</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.212937</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.221396</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>DM-52</th>\n      <td>0.330720</td>\n      <td>0.242236</td>\n      <td>0.012760</td>\n      <td>0.012110</td>\n      <td>0.256973</td>\n      <td>0.000000</td>\n      <td>0.010207</td>\n      <td>0.011319</td>\n      <td>0.000000</td>\n      <td>0.010514</td>\n      <td>...</td>\n      <td>0.011526</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>DM-78</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010642</td>\n      <td>0.010101</td>\n      <td>0.010015</td>\n      <td>0.837085</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>DM-16286</th>\n      <td>0.116978</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.560591</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.227189</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>DM-18223</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.129856</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.141204</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.254563</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>DM-18209</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.154350</td>\n      <td>0.148349</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.150610</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>DM-16305</th>\n      <td>0.018436</td>\n      <td>0.017443</td>\n      <td>0.021201</td>\n      <td>0.020122</td>\n      <td>0.019952</td>\n      <td>0.013864</td>\n      <td>0.016960</td>\n      <td>0.018808</td>\n      <td>0.015973</td>\n      <td>0.017469</td>\n      <td>...</td>\n      <td>0.019150</td>\n      <td>0.015363</td>\n      <td>0.016178</td>\n      <td>0.013489</td>\n      <td>0.016555</td>\n      <td>0.015846</td>\n      <td>0.013893</td>\n      <td>0.016012</td>\n      <td>0.675587</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>DM-16304</th>\n      <td>0.349271</td>\n      <td>0.017445</td>\n      <td>0.351930</td>\n      <td>0.020124</td>\n      <td>0.019954</td>\n      <td>0.013865</td>\n      <td>0.016961</td>\n      <td>0.018809</td>\n      <td>0.015974</td>\n      <td>0.017470</td>\n      <td>...</td>\n      <td>0.019152</td>\n      <td>0.015364</td>\n      <td>0.016180</td>\n      <td>0.013490</td>\n      <td>0.016557</td>\n      <td>0.015847</td>\n      <td>0.013894</td>\n      <td>0.016013</td>\n      <td>0.013999</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3227 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}